[2023-04-15 16:15:56.522512: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:113] mmap allocating space 12.03 GB
[2023-04-15 16:15:56.522634: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:118] mmap allocating space 12.03 GB done
[2023-04-15 16:15:56.522672: E /samgraph/samgraph/common/common.cc:229] From MMAP reading disk 12.03 GB
[2023-04-15 16:16:02.277866: E /samgraph/samgraph/common/common.cc:243] From MMAP reading done
[2023-04-15 16:16:04.716334: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.03 GB
[2023-04-15 16:16:05.357318: E /samgraph/samgraph/common/engine.cc:277] Train set size 7.64 MB
[2023-04-15 16:16:05.358023: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:113] mmap allocating space 68.50 GB
[2023-04-15 16:16:05.358071: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:118] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2023-04-15 16:16:05.502237: W /samgraph/samgraph/common/dist/dist_engine.cc:687] Trainer[0] initializing...
[2023-04-15 16:16:05.603887: W /samgraph/samgraph/common/dist/dist_engine.cc:687] Trainer[1] initializing...
[2023-04-15 16:16:05.605631: W /samgraph/samgraph/common/dist/dist_engine.cc:687] Trainer[2] initializing...
[2023-04-15 16:16:06.999231: W /samgraph/samgraph/common/dist/dist_engine.cc:691] Trainer[0] pin memory queue...
[2023-04-15 16:16:07. 51465: W /samgraph/samgraph/common/dist/dist_engine.cc:691] Trainer[2] pin memory queue...
[2023-04-15 16:16:07. 63713: W /samgraph/samgraph/common/dist/dist_engine.cc:691] Trainer[1] pin memory queue...
[2023-04-15 16:16:46.836193: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-04-15 16:16:46.836820: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[2] register host memory...
[2023-04-15 16:16:46.837379: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-04-15 16:16:46.837947: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[0] register host memory...
[2023-04-15 16:16:46.854201: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-04-15 16:16:46.854304: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[1] register host memory...
[2023-04-15 16:16:47.128963: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-04-15 16:16:47.137111: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 423.66 MB
[2023-04-15 16:16:47.245535: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 12.03 GB
[2023-04-15 16:16:50. 30015: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2023-04-15 16:16:50. 39299: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2023-04-15 16:16:50. 47935: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2023-04-15 16:16:50. 47999: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 847.32 MB
[2023-04-15 16:16:50.632996: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2023-04-15 16:16:59.819865: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 4.65572 on sample, 0.367498 on copy, 4.14926 on count
[2023-04-15 16:16:59.819989: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2023-04-15 16:17:08.687502: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 9.23493 on sample, 0.730753 on copy, 8.06233 on count
[2023-04-15 16:17:08.687643: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1175765, min_num_inputs = 1133105
[2023-04-15 16:17:09.135245: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.447479 on sort freq.
[2023-04-15 16:17:09.738718: E /samgraph/samgraph/common/dist/dist_engine.cc:549] pre sample done, delete it
[[[2023-04-15 16:17:092023-04-15 16:17:092023-04-15 16:17:09...891226891226891229: : : WWW   /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:::736736736] ] ] Trainer[0] building cache...Trainer[1] building cache...Trainer[2] building cache...


[[2023-04-15 16:17:092023-04-15 16:17:09..893022893033: : EE  /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc::298298] ] before scale, dtype is 0, dim is 128before scale, dtype is 0, dim is 128

[[2023-04-15 16:17:092023-04-15 16:17:09..893123893125: : EE  /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc::304304] ] after scale, dtype is 7, new dim is 32after scale, dtype is 7, new dim is 32

[2023-04-15 16:17:09.893715: E [/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2023-04-15 16:17:09:.207893734] : assigning 0 to cpuE
 /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:207] assigning 0 to cpu
[2023-04-15 16:17:09.893783: E[ 2023-04-15 16:17:09/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.:893799224: ] Ebuild symm link desc with 3X Tesla V100-SXM2-16GB out of 4 
/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:224] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4[
2023-04-15 16:17:09.893852: [E2023-04-15 16:17:09 ./samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc893868:: 225E]  remote time is 9.21053/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:225] [remote time is 9.210532023-04-15 16:17:09
.893915: [E2023-04-15 16:17:09 ./samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc893932:: 226E]  cpu time is 31.8182/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc
:226] cpu time is 31.8182
[2023-04-15 16:17:09.893996[: 2023-04-15 16:17:09E. 894004/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc: :E314 ] /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.ccregistering cpu data with 16.00 GB:
314] registering cpu data with 16.00 GB
[2023-04-15 16:17:09.894298: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:298] before scale, dtype is 0, dim is 128
[2023-04-15 16:17:09.894424: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:304] after scale, dtype is 7, new dim is 32
[2023-04-15 16:17:09.899299: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:207] assigning 0 to cpu
[2023-04-15 16:17:09.899434: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:224] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2023-04-15 16:17:09.899553: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:225] remote time is 9.21053
[2023-04-15 16:17:09.899649: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:226] cpu time is 31.8182
[2023-04-15 16:17:09.899776: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:314] registering cpu data with 16.00 GB
[2023-04-15 16:17:13.372910: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:316] registering cpu data done.
[2023-04-15 16:17:13.373803: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:316] registering cpu data done.
[2023-04-15 16:17:13.385056: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:316] registering cpu data done.
[2023-04-15 16:17:13.385136: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:109] creating solver
[2023-04-15 16:17:13.385175: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:149] solver created. now build & solve
[2023-04-15 16:17:13.431643: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:154] solver built. now solve
[2023-04-15 16:17:13.431712: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:1474] num_cached_nodes = 21101391
[2023-04-15 16:17:13.747854: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:158] solver solved
[2023-04-15 16:17:13.748084: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:326] 0 solved master
[2023-04-15 16:17:13.748204: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:333] 0 solved
[2023-04-15 16:17:13.748299: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:336] worker 0 thread 0 initing device 0
[2023-04-15 16:17:13.751990: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2320] Building Coll Cache with ... num gpu device is 3
[2023-04-15 16:17:13.752155: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cuh:611] per src size local is 23211630
[2023-04-15 16:17:13.793779: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:333] 2 solved
[2023-04-15 16:17:13.793875: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:336] worker 2 thread 2 initing device 2
[2023-04-15 16:17:13.795979: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2320] Building Coll Cache with ... num gpu device is 3
[2023-04-15 16:17:13.810972: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:333] 1 solved
[2023-04-15 16:17:13.811057: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:336] worker 1 thread 1 initing device 1
[2023-04-15 16:17:13.813104: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2320] Building Coll Cache with ... num gpu device is 3
[2023-04-15 16:17:13.840839: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-04-15 16:17:13.840968: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2362] num cpu nodes is 89958565
[2023-04-15 16:17:13.903109: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-04-15 16:17:13.903225: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2362] num cpu nodes is 89958565
[2023-04-15 16:17:13.911491: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-04-15 16:17:13.911576: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2362] num cpu nodes is 89958565
[2023-04-15 16:17:14.751170: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 21101391 possible elem, scale to 67108864
[2023-04-15 16:17:14.751266: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 512.00 MB
[2023-04-15 16:17:14.825764: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 21101391 possible elem, scale to 67108864
[2023-04-15 16:17:14.825840: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 512.00 MB
[2023-04-15 16:17:14.827710: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 21101391 possible elem, scale to 67108864
[2023-04-15 16:17:14.827779: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 512.00 MB
[2023-04-15 16:17:14.853340: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?21212451->111060
[2023-04-15 16:17:14.853399: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?21212451->111060
[2023-04-15 16:17:14.853484: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?21212451->111060
[2023-04-15 16:17:14.878550: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2439] Asymm Coll cache (policy: rep_cache) | local 21101391 / 111059956 nodes ( 19.00 %~19.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 89958565 / 111059956 nodes ( 81.00 %) | 10.11 GB | 1.08251 secs 
[2023-04-15 16:17:14.892265: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2439] Asymm Coll cache (policy: rep_cache) | local 21101391 / 111059956 nodes ( 19.00 %~19.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 89958565 / 111059956 nodes ( 81.00 %) | 10.11 GB | 1.0791 secs 
[2023-04-15 16:17:14.895313: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2439] Asymm Coll cache (policy: rep_cache) | local 21101391 / 111059956 nodes ( 19.00 %~19.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 89958565 / 111059956 nodes ( 81.00 %) | 10.11 GB | 1.14324 secs 
[2023-04-15 16:17:16.670582: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 618.36 MB
[2023-04-15 16:17:16.671024: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 12.08 MB
[2023-04-15 16:17:16.671392: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 12.08 MB
[2023-04-15 16:17:16.700052: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 618.36 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

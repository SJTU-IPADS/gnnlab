[2022-12-08 13:56:48.550099: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 13.46 GB
[2022-12-08 13:56:48.550202: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 13.46 GB done
[2022-12-08 13:56:54.935494: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 62.57 GB
[2022-12-08 13:56:54.935620: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 62.57 GB done
[2022-12-08 13:56:54.935712: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 13.46 GB
[2022-12-08 13:56:55.710010: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-08 13:56:55.710809: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-08 13:56:55.710850: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-08 13:56:55.924295: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-08 13:56:55.924962: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-08 13:56:55.988962: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-08 13:56:57.402543: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-08 13:56:57.404562: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-08 13:56:57.408426: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-08 13:57:32.799626: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[[2022-12-08 13:57:322022-12-08 13:57:32..800084800108: : EW  /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc::85701] ] Running on V100Trainer[0] register host memory...

[2022-12-08 13:57:32.800552: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-08 13:57:32.823454: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:57:32.823551: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-08 13:57:33. 93071: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:57:33.101005: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 250.28 MB
[2022-12-08 13:57:33.171730: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 13.46 GB
[2022-12-08 13:57:36.287383: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-08 13:57:36.296605: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-08 13:57:36.305621: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-08 13:57:36.305669: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 500.55 MB
[2022-12-08 13:57:36.653408: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-08 13:57:50.510775: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 5.65745 on sample, 0.403361 on copy, 7.77934 on count
[2022-12-08 13:57:50.510879: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-08 13:58:03.857022: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 11.3184 on sample, 0.80128 on copy, 15.0497 on count
[2022-12-08 13:58:03.857155: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1276735, min_num_inputs = 1248037
[2022-12-08 13:58:04.103453: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.246194 on sort freq.
[2022-12-08 13:58:04.460427: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[2022-12-08 13:58:04.[552429: 2022-12-08 13:58:04W. 552432/samgraph/samgraph/common/dist/dist_engine.cc: :W[711 2022-12-08 13:58:04] /samgraph/samgraph/common/dist/dist_engine.cc.Trainer[1] building cache...552458:
: 711W]  Trainer[0] building cache.../samgraph/samgraph/common/dist/dist_engine.cc
:711] Trainer[2] building cache...
[2022-12-08 13:58:04.554615: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:58:04.554670: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:58:04.554699: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:58:04.554981: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:58:04.555089: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:58:04.555160: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:58:04.555520: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:58:04.555647: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:58:04.555725: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:59:16.582613: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-08 13:59:16.610079: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-08 13:59:16.610133: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 6560836
[2022-12-08 13:59:16.947282: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-08 13:59:16.947392: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-08 13:59:16.947435: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-08 13:59:16.947464: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-08 13:59:16.959268: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-08 13:59:16.959321: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 1 thread 1 initing device 1
[2022-12-08 13:59:16.959342: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-08 13:59:16.959391: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 2 thread 2 initing device 2
[2022-12-08 13:59:17.591880: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 6560836 / 65608366 nodes ( 10.00 %~10.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 59047530 / 65608366 nodes ( 90.00 %) | 6.26 GB | 0.630787 secs 
[2022-12-08 13:59:17.592018: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 6560836 / 65608366 nodes ( 10.00 %~10.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 59047530 / 65608366 nodes ( 90.00 %) | 6.26 GB | 0.630882 secs 
[2022-12-08 13:59:17.592081: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 6560836 / 65608366 nodes ( 10.00 %~10.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 59047530 / 65608366 nodes ( 90.00 %) | 6.26 GB | 0.6429 secs 
[2022-12-08 13:59:24.981378: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.31 GB
[2022-12-08 13:59:26.391656: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.31 GB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

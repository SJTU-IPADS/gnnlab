[2022-12-08 13:30:21.497790: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 13.46 GB
[2022-12-08 13:30:21.497891: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 13.46 GB done
[2022-12-08 13:30:27.210086: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 62.57 GB
[2022-12-08 13:30:27.210221: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 62.57 GB done
[2022-12-08 13:30:27.210313: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 13.46 GB
[2022-12-08 13:30:28. 67264: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-08 13:30:28. 67982: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-08 13:30:28. 68020: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-08 13:30:28.258609: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-08 13:30:28.264667: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-08 13:30:28.265780: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-08 13:30:29.713560: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-08 13:30:29.714753: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-08 13:30:29.715016: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-08 13:31:04.695248: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:31:04.695826[: 2022-12-08 13:31:04W. 695811/samgraph/samgraph/common/dist/dist_engine.cc: :E701 ] /samgraph/samgraph/common/dist/dist_engine.ccTrainer[0] register host memory...:
85] Running on V100
[2022-12-08 13:31:04.696357: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-08 13:31:04.720065: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:31:04.720153: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-08 13:31:04.999078: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:31:05.  7090: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 250.28 MB
[2022-12-08 13:31:05. 78405: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 13.46 GB
[2022-12-08 13:31:08.231133: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-08 13:31:08.240496: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-08 13:31:08.249489: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-08 13:31:08.249537: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 500.55 MB
[2022-12-08 13:31:08.598385: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-08 13:31:20.222220: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 5.49426 on sample, 0.399055 on copy, 5.7177 on count
[2022-12-08 13:31:20.222324: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-08 13:31:31.803990: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 10.9679 on sample, 0.793841 on copy, 11.418 on count
[2022-12-08 13:31:31.804112: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1283889, min_num_inputs = 1248450
[2022-12-08 13:31:32. 51752: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.247534 on sort freq.
[2022-12-08 13:31:32.422334: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[2022-12-08 13:31:32.2022-12-08 13:31:32518418: [W /samgraph/samgraph/common/dist/dist_engine.cc:711] Trainer[1] building cache...
.518413: W /samgraph/samgraph/common/dist/dist_engine.cc:711] Trainer[0] building cache...
2022-12-08 13:31:32.518416: W /samgraph/samgraph/common/dist/dist_engine.cc:711] Trainer[2] building cache...
[2022-12-08 13:31:32.522216: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-08 13:31:32.522827: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:31:32.522931: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:31:32.523007: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:31:32.524855: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:[1342022-12-08 13:31:32] .using concurrent impl MPS524906
: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-08 13:31:32.525969: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:[2002022-12-08 13:31:32] .build symm link desc with 3X Tesla V100-SXM2-16GB out of 4526009
: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:[2002022-12-08 13:31:32] .build symm link desc with 3X Tesla V100-SXM2-16GB out of 4526087
: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:[2012022-12-08 13:31:32] .remote time is 8.68421526145
: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc[:2022-12-08 13:31:32201.] 526196remote time is 8.68421: 
E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:[2022022-12-08 13:31:32] .cpu time is 30526257
: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:32:43.446479: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-08 13:32:43.476015: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
block 0 storage is 00000001
	access is	0	0	0	
block 1 storage is 00000010
	access is	1	1	1	
block 2 storage is 00000100
	access is	2	2	2	
block 3 storage is 00000000
	access is	3	3	3	
[2022-12-08 13:32:43.879009: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-08 13:32:43.879079: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-08 13:32:43.879120: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-08 13:32:43.879148: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-08 13:32:43.881000: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1766] Building Coll Cache with ... num gpu device is 3
[2022-12-08 13:32:43.890999: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-08 13:32:43.891051: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] [worker 1 thread 1 initing device 12022-12-08 13:32:43
.891059: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-08 13:32:43.891113: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 2 thread 2 initing device 2
[2022-12-08 13:32:43.892926: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1766] Building Coll Cache with ... num gpu device is 3
[2022-12-08 13:32:43.892991: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1766] Building Coll Cache with ... num gpu device is 3
[2022-12-08 13:32:43.946097: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 15.02 MB
[[[2022-12-08 13:32:442022-12-08 13:32:442022-12-08 13:32:44...314652314653314653: : : EEE   /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu/samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu/samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:::187718771877] ] ] Device 1 init p2p of link 2Device 0 init p2p of link 1Device 2 init p2p of link 0


[2022-12-08 13:32:44.319987: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1877] Device 1 init p2p of link 0
[2022-12-08 13:32:44.320067: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1877] Device 2 init p2p of link 1
[2022-12-08 13:32:44.320110: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1877] Device 0 init p2p of link 2
[2022-12-08 13:32:44.325173: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1906] Asymm Coll cache (policy: clique_part) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 7873002 / 65608366 nodes ( 12.00 %) | cpu 53798863 / 65608366 nodes ( 82.00 %) | 3.76 GB | 0.432205 secs 
[2022-12-08 13:32:44.325383: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1906] Asymm Coll cache (policy: clique_part) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 7873002 / 65608366 nodes ( 12.00 %) | cpu 53798863 / 65608366 nodes ( 82.00 %) | 3.76 GB | 0.432349 secs 
[2022-12-08 13:32:44.325510: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1906] Asymm Coll cache (policy: clique_part) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 7873002 / 65608366 nodes ( 12.00 %) | cpu 53798863 / 65608366 nodes ( 82.00 %) | 3.76 GB | 0.444467 secs 
[2022-12-08 13:32:44.325729: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] before create ctx, mem is 5.21 GB
[2022-12-08 13:32:45.777827: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2016] after create ctx, mem is 5.70 GB
[2022-12-08 13:32:45.777982: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2023] after create stream, mem is 5.70 GB
[2022-12-08 13:32:45.778432: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] before create ctx, mem is 5.70 GB
[2022-12-08 13:32:47.110029: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2016] after create ctx, mem is 6.19 GB
[2022-12-08 13:32:47.110152: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2023] after create stream, mem is 6.19 GB
[2022-12-08 13:32:47.110477: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] before create ctx, mem is 6.19 GB
[2022-12-08 13:32:48.459835: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2016] after create ctx, mem is 6.82 GB
[2022-12-08 13:32:48.459986: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2023] after create stream, mem is 6.82 GB
[2022-12-08 13:32:48.460259: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] before create ctx, mem is 6.82 GB
[2022-12-08 13:32:49.753781: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2016] after create ctx, mem is 7.20 GB
[2022-12-08 13:32:49.753899: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2023] after create stream, mem is 7.20 GB
[2022-12-08 13:32:57.333697: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.31 GB
[2022-12-08 13:32:57.334682: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 13.12 MB
[2022-12-08 13:32:57.335230: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 13.12 MB
[2022-12-08 13:32:58.595513: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.31 GB
[2022-12-08 13:32:58.600681: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 12.05 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

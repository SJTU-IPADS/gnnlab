[2022-12-05 16:02:28.469162: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 12.03 GB
[2022-12-05 16:02:28.469266: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 12.03 GB done
[2022-12-05 16:02:33.595753: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 52.96 GB
[2022-12-05 16:02:33.595858: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 52.96 GB done
[2022-12-05 16:02:33.595938: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.03 GB
[2022-12-05 16:02:34.428526: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-05 16:02:34.429258: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-05 16:02:34.429296: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-05 16:02:34.590766: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-05 16:02:34.683981: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-05 16:02:34.737130: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-05 16:02:36. 92458: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-05 16:02:36.128322: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-05 16:02:36.140143: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-05 16:02:58.712282: E /samgraph/samgraph/common/dist/dist_engine.cc:85[] 2022-12-05 16:02:58Running on V100.
712340: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:02:58.712843: W[ 2022-12-05 16:02:58/samgraph/samgraph/common/dist/dist_engine.cc.:712860701: ] WTrainer[2] register host memory... 
/samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-05 16:02:58.737685: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:02:58.737762: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[0] register host memory...
[2022-12-05 16:02:58.950855: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:02:58.956241: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 423.66 MB
[2022-12-05 16:02:59. 71898: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 12.03 GB
[2022-12-05 16:03:02. 51017: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-05 16:03:02. 56431: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-05 16:03:02. 61548: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-05 16:03:02. 61595: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 847.32 MB
[2022-12-05 16:03:02.356335: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-05 16:03:11.830908: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 4.58653 on sample, 0.365517 on copy, 4.51033 on count
[2022-12-05 16:03:11.831007: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-05 16:03:21.317720: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 9.14808 on sample, 0.729213 on copy, 9.06051 on count
[2022-12-05 16:03:21.317859: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1175694, min_num_inputs = 1137658
[2022-12-05 16:03:21.611432: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.293485 on sort freq.
[2022-12-05 16:03:21.956919: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[[2022-12-05 16:03:212022-12-05 16:03:21.2022-12-05 16:03:21.982939982943.: 982946: W: W W /samgraph/samgraph/common/dist/dist_engine.cc /samgraph/samgraph/common/dist/dist_engine.cc:/samgraph/samgraph/common/dist/dist_engine.cc:711:711] 711] Trainer[0] building cache...Trainer[2] building cache...] 

Trainer[1] building cache...
[2022-12-05 16:03:21.985479: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 16:03:21.985549: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 8.68421
[2022-12-05 16:03:21.985590: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 16:03:21.985906: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 16:03:21[.2022-12-05 16:03:21985951.: 985990E:  E/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc196:] 197build symm link desc with 3X Tesla V100-SXM2-16GB out of 4] 
remote time is 8.68421
[2022-12-05 16:03:21[.2022-12-05 16:03:21986086.: 986089E:  E/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc198:] 197cpu time is 30] 
remote time is 8.68421
[2022-12-05 16:03:21.986189: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 16:03:39.327837: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:115] solver created. now build & solve
[2022-12-05 16:03:39.373838: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:120] solver built. now solve
[2022-12-05 16:03:39.373892: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 8884796
[2022-12-05 16:03:39.861171: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:124] solver solved
[2022-12-05 16:03:39.861267: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:187] 0 solved master
[2022-12-05 16:03:39.861310: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 0 solved
[2022-12-05 16:03:39.861338: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 0 thread 0 initing device 0
[2022-12-05 16:03:39.881081: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 2 solved
[2022-12-05 16:03:39.881136: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 2 thread 2 initing device 2
[2022-12-05 16:03:39.881258: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 1 solved
[2022-12-05 16:03:39.881306: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 1 thread 1 initing device 1
[2022-12-05 16:03:40.373007: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 8884796 / 111059956 nodes ( 8.00 %~8.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 102175160 / 111059956 nodes ( 92.00 %) | 4.24 GB | 0.490735 secs 
[2022-12-05 16:03:40.373562: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 8884796 / 111059956 nodes ( 8.00 %~8.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 102175160 / 111059956 nodes ( 92.00 %) | 4.24 GB | 0.491187 secs 
[2022-12-05 16:03:40.374069: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 8884796 / 111059956 nodes ( 8.00 %~8.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 102175160 / 111059956 nodes ( 92.00 %) | 4.24 GB | 0.511693 secs 
[2022-12-05 16:03:46.742635: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 615.60 MB
[2022-12-05 16:03:47.927364: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 615.60 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

[2022-12-08 13:34:40.897290: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 13.46 GB
[2022-12-08 13:34:40.897394: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 13.46 GB done
[2022-12-08 13:34:47.841944: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 62.57 GB
[2022-12-08 13:34:47.842075: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 62.57 GB done
[2022-12-08 13:34:47.842176: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 13.46 GB
[2022-12-08 13:34:48.708968: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-08 13:34:48.709658: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-08 13:34:48.709697: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-08 13:34:48.904520: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-08 13:34:48.967748: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-08 13:34:48.977999: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-08 13:34:50.347921: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-08 13:34:50.353725: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-08 13:34:50.357632: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-08 13:35:14.620179: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:35:14.620663: [W2022-12-08 13:35:14 ./samgraph/samgraph/common/dist/dist_engine.cc620647:: 701E]  Trainer[0] register host memory.../samgraph/samgraph/common/dist/dist_engine.cc
:85] Running on V100
[2022-12-08 13:35:14.621121: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-08 13:35:14.623104: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:35:14.623427: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-08 13:35:14.873269: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-08 13:35:14.878314: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 250.28 MB
[2022-12-08 13:35:14.949488: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 13.46 GB
[2022-12-08 13:35:18. 88492: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-08 13:35:18. 93831: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-08 13:35:18. 98907: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-08 13:35:18. 98956: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 500.55 MB
[2022-12-08 13:35:18.271159: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-08 13:35:28.919595: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 5.483 on sample, 0.397801 on copy, 4.75583 on count
[2022-12-08 13:35:28.919715: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-08 13:35:39.700937: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 10.9413 on sample, 0.792809 on copy, 9.67158 on count
[2022-12-08 13:35:39.701077: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1277844, min_num_inputs = 1247233
[2022-12-08 13:35:39.892851: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.191689 on sort freq.
[2022-12-08 13:35:40.105412: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[[2022-12-08 13:35:402022-12-08 13:35:402022-12-08 13:35:40...120706120706120702: : : WWW   /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:::711711711] ] ] Trainer[2] building cache...Trainer[1] building cache...Trainer[0] building cache...


[2022-12-08 13:35:40.127990: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:35:40.128097: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:35:40.128158: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:35:40.130668: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:35:40.130729: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:35:40.130758: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:35:40.130774: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:200] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-08 13:35:40.130832: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:201] remote time is 8.68421
[2022-12-08 13:35:40.130862: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:202] cpu time is 30
[2022-12-08 13:37:00.302540: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-08 13:37:00.332846: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-08 13:37:00.332907: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 3936501
[2022-12-08 13:37:00.725129: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-08 13:37:00.725230: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-08 13:37:00.725272: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-08 13:37:00.725300: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-08 13:37:00.737152: E [/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc2022-12-08 13:37:00:.202737174] : 2 solvedE
 /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202[] 2022-12-08 13:37:001 solved.
737223: E [/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc2022-12-08 13:37:00:.205737242] : worker 2 thread 2 initing device 2E
 /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 1 thread 1 initing device 1
[2022-12-08 13:37:01.142029: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 61671865 / 65608366 nodes ( 94.00 %) | 3.75 GB | 0.414833 secs 
[2022-12-08 13:37:01.142174: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 61671865 / 65608366 nodes ( 94.00 %) | 3.75 GB | 0.40295 secs 
[2022-12-08 13:37:01.142223: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 3936501 / 65608366 nodes ( 6.00 %~6.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 61671865 / 65608366 nodes ( 94.00 %) | 3.75 GB | 0.403043 secs 
[2022-12-08 13:37:08.617810: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.32 GB
[2022-12-08 13:37:10. 62600: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.32 GB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

[2023-03-30 16:45:06.631224: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:113] mmap allocating space 12.87 GB
[2023-03-30 16:45:06.631325: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:118] mmap allocating space 12.87 GB done
[2023-03-30 16:45:06.631354: E /samgraph/samgraph/common/common.cc:229] From MMAP reading disk 12.87 GB
[2023-03-30 16:45:12.264830: E /samgraph/samgraph/common/common.cc:243] From MMAP reading done
[2023-03-30 16:45:18.227874: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:113] mmap allocating space 1.82 GB
[2023-03-30 16:45:18.227959: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:118] mmap allocating space 1.82 GB done
[2023-03-30 16:45:18.228039: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.87 GB
[2023-03-30 16:45:18.749746: E /samgraph/samgraph/common/engine.cc:277] Train set size 3.81 MB
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2023-03-30 16:45:25.627040: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:25.659762: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:25.665839: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:25.703608: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:25.707654: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 931.40 MB
[2023-03-30 16:45:25.968855: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 16.09 GB
[2023-03-30 16:45:36.329799: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 32.00 MB
[2023-03-30 16:45:36.333056: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2023-03-30 16:45:36.336072: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2023-03-30 16:45:36.336118: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 1.82 GB
[2023-03-30 16:45:36.997101: E /samgraph/samgraph/common/dist/dist_engine.cc:531] worker 0 placing graph to gpu
[2023-03-30 16:45:38.139882: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2023-03-30 16:45:41.524032: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 2.00266 on sample, 0.161158 on copy, 1.20668 on count
[2023-03-30 16:45:41.524177: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2023-03-30 16:45:44.905028: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 3.99269 on sample, 0.320921 on copy, 2.42423 on count
[2023-03-30 16:45:44.905166: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 500629, min_num_inputs = 464032
[2023-03-30 16:45:45.502790: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.597528 on sort freq.
[2023-03-30 16:45:46.266810: E /samgraph/samgraph/common/dist/dist_engine.cc:549] pre sample done, delete it
[[[2023-03-30 16:45:462023-03-30 16:45:462023-03-30 16:45:46...326769326783326779: : : WWW   /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:::687687687] ] ] Trainer[1] initializing...Trainer[0] initializing...Trainer[3] initializing...


[2023-03-30 16:45:46.326922: W /samgraph/samgraph/common/dist/dist_engine.cc:691] Trainer[1] pin memory queue...
[2023-03-30 16:45:46.326942: [W2023-03-30 16:45:46 ./samgraph/samgraph/common/dist/dist_engine.cc326957:: 691W]  Trainer[0] pin memory queue.../samgraph/samgraph/common/dist/dist_engine.cc
:691] Trainer[3] pin memory queue...
[2023-03-30 16:45:46.327083: W /samgraph/samgraph/common/dist/dist_engine.cc:687] Trainer[2] initializing...
[2023-03-30 16:45:46.327314: W /samgraph/samgraph/common/dist/dist_engine.cc:691] Trainer[2] pin memory queue...
[2023-03-30 16:45:46.327777: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:46.327876: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[1] register host memory...
[2023-03-30 16:45:46.328028: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100[
2023-03-30 16:45:46.328059: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:46.328117: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[0] register host memory...
[2023-03-30 16:45:46.328178: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[3] register host memory...
[2023-03-30 16:45:46.328355: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2023-03-30 16:45:46.328486: W /samgraph/samgraph/common/dist/dist_engine.cc:726] Trainer[2] register host memory...
[2023-03-30 16:45:46.328572[: [[2023-03-30 16:45:46W2023-03-30 16:45:462023-03-30 16:45:46. ..328575/samgraph/samgraph/common/dist/dist_engine.cc328577328576: :: : W736WW ]   /samgraph/samgraph/common/dist/dist_engine.ccTrainer[1] building cache.../samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:
::736736736] ] ] Trainer[0] building cache...Trainer[3] building cache...Trainer[2] building cache...


[2023-03-30 16:45:46.330632: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 0 to cpu
[2023-03-30 16:45:46.330717: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:212] build symm link desc with 4X Tesla V100-SXM2-16GB out of 4
[2023-03-30 16:45:46.330775: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213] remote time is 8.68421
[2023-03-30 16:45:46.330821: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 30
[2023-03-30 16:45:46.330878: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:255] registering cpu data with 48.00 GB
[2023-03-30 16:45:46.331031: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 0 to cpu
[2023-03-30 16:45:46.331086: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:212] build symm link desc with 4X Tesla V100-SXM2-16GB out of 4
[2023-03-30 16:45:46.331120: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213] remote time is 8.68421
[2023-03-30 16:45:46.331148: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 30
[2023-03-30 16:45:46.331182: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:255] registering cpu data with 48.00 GB
[2023-03-30 16:45:46.331435: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 0 to cpu
[2023-03-30 16:45:46.331516: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:212] build symm link desc with 4X Tesla V100-SXM2-16GB out of 4
[2023-03-30 16:45:46.331570: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213] remote time is 8.68421
[2023-03-30 16:45:46.331618: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 30
[2023-03-30 16:45:46.331672: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:255] registering cpu data with 48.00 GB
[2023-03-30 16:45:46.332336: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] assigning 0 to cpu
[2023-03-30 16:45:46.332466: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:212] build symm link desc with 4X Tesla V100-SXM2-16GB out of 4
[2023-03-30 16:45:46.332554: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:213] remote time is 8.68421
[2023-03-30 16:45:46.332630: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:214] cpu time is 30
[2023-03-30 16:45:46.332717: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:255] registering cpu data with 48.00 GB
[2023-03-30 16:45:56.169319: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:257] registering cpu data done.
[2023-03-30 16:45:56.169814: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:257] registering cpu data done.
[2023-03-30 16:45:56.170255: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:257] registering cpu data done.
[2023-03-30 16:45:56.183955: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:257] registering cpu data done.
[2023-03-30 16:45:56.184015: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:78] creating solver
[2023-03-30 16:45:56.184043: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2023-03-30 16:45:56.287177: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2023-03-30 16:45:56.287226: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:1420] num_cached_nodes = 4883209
[2023-03-30 16:45:56.831283: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2023-03-30 16:45:56.831443: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:267] 0 solved master
[2023-03-30 16:45:56.831499: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:274] 0 solved
[2023-03-30 16:45:56.831532: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:277] worker 0 thread 0 initing device 0
[2023-03-30 16:45:56.835345: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2265] Building Coll Cache with ... num gpu device is 4
[2023-03-30 16:45:56.837006: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cuh:611] per src size local is 5371629
[2023-03-30 16:45:56.899219: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-03-30 16:45:56.899268: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2307] num cpu nodes is 239277290
[2023-03-30 16:45:56.901900: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:274] 3 solved
[2023-03-30 16:45:56.901967: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:277] worker 3 thread 3 initing device 3
[2023-03-30 16:45:56.902842: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:274] 1 solved
[2023-03-30 16:45:56.902896: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:277] worker 1 thread 1 initing device 1
[2023-03-30 16:45:56.907415: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2265] Building Coll Cache with ... num gpu device is 4
[2023-03-30 16:45:56.908017: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2265] Building Coll Cache with ... num gpu device is 4
[2023-03-30 16:45:56.915501: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:274] 2 solved
[2023-03-30 16:45:56.915624: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:277] worker 2 thread 2 initing device 2
[2023-03-30 16:45:56.917910: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2265] Building Coll Cache with ... num gpu device is 4
[2023-03-30 16:45:57. 15559: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-03-30 16:45:57. 15652: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2307] num cpu nodes is 239277290
[2023-03-30 16:45:57. 17370: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-03-30 16:45:57. 17430: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2307] num cpu nodes is 239277290
[2023-03-30 16:45:57. 25557: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:261] making a tensor with 0 num item
[2023-03-30 16:45:57. 25622: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2307] num cpu nodes is 239277290
[2023-03-30 16:45:57.538153: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 4883209 possible elem, scale to 16777216
[2023-03-30 16:45:57.538226: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 128.00 MB
[2023-03-30 16:45:57.655106: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 4883209 possible elem, scale to 16777216
[2023-03-30 16:45:57.655166: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 128.00 MB
[2023-03-30 16:45:57.656084: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 4883209 possible elem, scale to 16777216
[2023-03-30 16:45:57.656137: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 128.00 MB
[2023-03-30 16:45:57.656313: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:355] create a hashtable with 4883209 possible elem, scale to 16777216
[2023-03-30 16:45:57.656367: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cuda/cache_hashtable.cu:360] SimpleHashTable allocating 128.00 MB
[2023-03-30 16:45:57.669543: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?5127370->244161
[2023-03-30 16:45:57.669617: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?5127370->244161
[2023-03-30 16:45:57.669739: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?5127370->244161
[2023-03-30 16:45:57.670773: E /samgraph/3rdparty/collcachelib/coll_cache_lib/common.cc:107] too many mem allocated for forcescale?5127370->244161
[2023-03-30 16:45:57.718580: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2383] Asymm Coll cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 7.33 GB | 0.883176 secs 
[2023-03-30 16:45:57.722547: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2383] Asymm Coll cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 7.33 GB | 0.815089 secs 
[[2023-03-30 16:45:572023-03-30 16:45:57..730540730540: : EE  /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu/samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu::23832383] ] Asymm Coll cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 7.33 GB | 0.822479 secs Asymm Coll cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 7.33 GB | 0.812553 secs 

[2023-03-30 16:45:58.457130: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 797.64 MB
[2023-03-30 16:45:59.428548: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 797.64 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

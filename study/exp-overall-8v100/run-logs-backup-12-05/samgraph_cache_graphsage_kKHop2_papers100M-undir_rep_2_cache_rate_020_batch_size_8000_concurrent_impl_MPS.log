config:eval_tsp="2022-12-07 03:49:39"
config:arch=arch5
config:num_train_worker=6
config:num_sample_worker=2
config:sample_type=khop2
config:root_path=/nvme/samgraph/
config:dataset=papers100M-undir
config:pipeline=False
config:cache_policy=rep
config:cache_percentage=0.2
config:num_epoch=4
config:batch_size=8000
config:num_hidden=256
config:max_sampling_jobs=1
config:max_copying_jobs=1
config:barriered_epoch=1
config:presample_epoch=2
config:omp_thread_num=6
config:unsupervised=False
config:amp=True
config:rolling=0
config:fanout=[25, 10]
config:lr=0.003
config:dropout=0.5
config:single_gpu=False
config:max_num_step=100000
config:validate_configs=False
config:report_acc=0
config:dataset_path=/nvme/samgraph/papers100M-undir
config:torch_thread_num=8
config:train_workers=['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3', 'cuda:4', 'cuda:5']
config:sample_workers=['cuda:6', 'cuda:7']
config:num_fanout=2
config:num_layer=2
config:_run_mode=RunMode.FGNN
config:_log_level=warn
config:_profile_level=3
config:_empty_feat=0
config:_arch=5
config:_sample_type=5
config:_cache_policy=12
test_result:init:input_scale_factor=1.1
coll_cache:optimal_rep_storage=0.2
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.8
coll_cache:optimal_local_storage=0.2
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=1
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0
z=299.804
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
coll_cache:optimal_rep_storage=0.2
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.8
coll_cache:optimal_local_storage=0.2
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=1
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0
z=299.804
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
[Train  Worker 5/6] Started with PID 38843(Tesla V100-SXM2-32GB)
[Train  Worker 5] run train for 4 epochs with 156 steps
[Train  Worker 5] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.3239 | Copy Time 0.1304
[Train  Worker 3/6] Started with PID 38838(Tesla V100-SXM2-32GB)
[Train  Worker 3] run train for 4 epochs with 156 steps
[Train  Worker 3] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.2491 | Copy Time 0.2052
[Train  Worker 2/6] Started with PID 38835(Tesla V100-SXM2-32GB)
[Train  Worker 2] run train for 4 epochs with 156 steps
[Train  Worker 2] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.2647 | Copy Time 0.1899
[Train  Worker 1/6] Started with PID 38832(Tesla V100-SXM2-32GB)
[Train  Worker 1] run train for 4 epochs with 156 steps
[Train  Worker 1] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.2573 | Copy Time 0.1968
[Train  Worker 4/6] Started with PID 38840(Tesla V100-SXM2-32GB)
[Train  Worker 4] run train for 4 epochs with 156 steps
[Train  Worker 4] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.2479 | Copy Time 0.2064
[Train  Worker 0/6] Started with PID 38829(Tesla V100-SXM2-32GB)
[Train  Worker 0] run train for 4 epochs with 156 steps
Epoch 00000 | Epoch Time 2.0378 | Total Train Time(Profiler) 1.8704 | Copy Time 0.1638
Epoch 00001 | Epoch Time 0.4586 | Total Train Time(Profiler) 0.3263 | Copy Time 0.1295
Epoch 00002 | Epoch Time 0.4570 | Total Train Time(Profiler) 0.3241 | Copy Time 0.1295
Epoch 00003 | Epoch Time 0.4572 | Total Train Time(Profiler) 0.3243 | Copy Time 0.1298
[Train  Worker 0] Avg Epoch Time 0.4576 | Train Total Time(Profiler) 0.3249 | Copy Time 0.1296
[Sample Worker 1/2] Started with PID 38827(Tesla V100-SXM2-32GB)
[Sample Worker 1] run sample for 4 epochs with 78 steps
[Sample Worker 1] Avg Sample Total Time 0.6013 | Sampler Total Time(Profiler) 0.5937
    [Step(average) Profiler Level 1 E3 S77]
        L1  sample           0.006247 | send           0.001483
        L1  recv             0.000000 | copy           0.000000 | convert time 0.000000 | train  0.000000
        L1  feature nbytes 0.00 Bytes | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes         1099575 | num samples     1708900
    [Step(average) Profiler Level 2 E3 S77]
        L2  shuffle     0.000612 | core sample  0.002135 | id remap        0.003384
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.000000
        L2  last layer sample time 0.000364 | size 72318.423077
    [Step(average) Profiler Level 3 E3 S77]
        L3  khop sample coo  0.001797 | khop sort coo      0.000000 | khop count edge     0.000045 | khop compact edge 0.000250
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.002763 | remap mapnode       0.000000 | remap mapedge     0.000620
        L3  cache get_index  0.000000 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.000000 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Init Profiler Level 1]
        L1  init     7.6250 | sampler init    16.0054 | trainer init 0.0000
    [Init Profiler Level 2]
        L2  load ds        10.2329 | init queue           5.5973
        L2  presample       5.3980 | build interal ds     2.3983
        L2  build cache     0.0000
    [Init Profiler Level 3]
        L3  load dataset: mmap     7.6202 | copy         2.6127
        L3  dist queue: alloc      0.0019 | pin          5.5954 | push     0.0000
        L3  presample: init        0.3764
        L3  presample: sample      1.8065 | copy         0.1153
        L3  presample: count       2.4516 | sort         0.2110
        L3  presample: reset       0.0006 | get rank     0.0240
        L3  internal: cuda ctx     2.1194 | cuda stream     0.2718
[Sample Worker 0/2] Started with PID 38826(Tesla V100-SXM2-32GB)
[Sample Worker 0] run sample for 4 epochs with 78 steps
[Sample Worker 0] Avg Sample Total Time 0.6037 | Sampler Total Time(Profiler) 0.6029
test_result:sample_time=0.4872
test_result:get_cache_miss_index_time=0.0000
test_result:enqueue_samples_time=0.1157
test_result:epoch_time:sample_total=0.6037
[CUDA] cuda0: usage: 17.04 GB
[SAM] cuda0 data alloc        : 0.00 Bytes
[SAM] cuda0 workspace         : 1.22 GB
[SAM] cuda0 workspace reserve : 618.58 MB
[SAM] cuda0 total             : 1.22 GB
    [Step(average) Profiler Level 1 E3 S155]
        L1  sample           0.000000 | send           0.000000
        L1  recv             0.002504 | copy           0.006782 | convert time 0.000542 | train  0.010152
        L1  feature nbytes  536.91 MB | label nbytes   62.50 KB
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes       9.30 MB | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
    [Step(average) Profiler Level 2 E3 S155]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000005 | id copy      0.000000 | cache feat copy 0.004273
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S155]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000814 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.002883 | cache combine cache 0.001959 | cache combine remote 0.000000
        L3  label extract  0.000443
    [Init Profiler Level 1]
        L1  init     7.6250 | sampler init     0.0000 | trainer init 52.7811
    [Init Profiler Level 2]
        L2  load ds         7.6202 | init queue           5.4779
        L2  presample       0.0000 | build interal ds     2.1367
        L2  build cache    45.1615
    [Init Profiler Level 3]
        L3  load dataset: mmap     7.6202 | copy         0.0000
        L3  dist queue: alloc      0.0019 | pin          5.4760 | push     0.0000
        L3  presample: init        0.0000
        L3  presample: sample      0.0000 | copy         0.0000
        L3  presample: count       0.0000 | sort         0.0000
        L3  presample: reset       0.0000 | get rank     0.0000
        L3  internal: cuda ctx     2.1367 | cuda stream     0.0001
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   22914 KB |  402981 KB |  145081 MB |  145059 MB |
|       from large pool |   18234 KB |  399595 KB |  144003 MB |  143986 MB |
|       from small pool |    4680 KB |    7122 KB |    1077 MB |    1073 MB |
|---------------------------------------------------------------------------|
| Active memory         |   22914 KB |  402981 KB |  145081 MB |  145059 MB |
|       from large pool |   18234 KB |  399595 KB |  144003 MB |  143986 MB |
|       from small pool |    4680 KB |    7122 KB |    1077 MB |    1073 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  577536 KB |  577536 KB |  577536 KB |       0 B  |
|       from large pool |  569344 KB |  569344 KB |  569344 KB |       0 B  |
|       from small pool |    8192 KB |    8192 KB |    8192 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24189 KB |  368952 KB |  170652 MB |  170628 MB |
|       from large pool |   22726 KB |  367129 KB |  169418 MB |  169396 MB |
|       from small pool |    1463 KB |    3616 KB |    1233 MB |    1232 MB |
|---------------------------------------------------------------------------|
| Allocations           |      38    |      51    |   11583    |   11545    |
|       from large pool |       3    |      14    |    4576    |    4573    |
|       from small pool |      35    |      39    |    7007    |    6972    |
|---------------------------------------------------------------------------|
| Active allocs         |      39    |      51    |   11583    |   11544    |
|       from large pool |       3    |      14    |    4576    |    4573    |
|       from small pool |      36    |      39    |    7007    |    6971    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      13    |      13    |      13    |       0    |
|       from large pool |       9    |       9    |       9    |       0    |
|       from small pool |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      12    |      24    |    5213    |    5201    |
|       from large pool |       4    |      12    |    2622    |    2618    |
|       from small pool |       8    |      15    |    2591    |    2583    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

test_result:epoch_time:copy_time=0.1296
test_result:convert_time=0.0137
test_result:train_time=0.3112
test_result:epoch_time:train_total=0.3249
test_result:cache_percentage=0.2000
test_result:cache_hit_rate=1.0000
test_result:run_time=5.8575

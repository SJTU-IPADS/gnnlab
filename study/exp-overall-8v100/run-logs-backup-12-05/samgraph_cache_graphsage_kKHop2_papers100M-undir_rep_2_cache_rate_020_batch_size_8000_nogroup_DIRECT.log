config:eval_tsp="2022-12-07 03:48:26"
config:arch=arch5
config:num_train_worker=6
config:num_sample_worker=2
config:sample_type=khop2
config:root_path=/nvme/samgraph/
config:dataset=papers100M-undir
config:pipeline=False
config:cache_policy=rep
config:cache_percentage=0.2
config:num_epoch=4
config:batch_size=8000
config:num_hidden=256
config:max_sampling_jobs=1
config:max_copying_jobs=1
config:barriered_epoch=1
config:presample_epoch=2
config:omp_thread_num=6
config:unsupervised=False
config:amp=True
config:rolling=0
config:fanout=[25, 10]
config:lr=0.003
config:dropout=0.5
config:single_gpu=False
config:max_num_step=100000
config:validate_configs=False
config:report_acc=0
config:dataset_path=/nvme/samgraph/papers100M-undir
config:torch_thread_num=8
config:train_workers=['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3', 'cuda:4', 'cuda:5']
config:sample_workers=['cuda:6', 'cuda:7']
config:num_fanout=2
config:num_layer=2
config:_run_mode=RunMode.FGNN
config:_log_level=warn
config:_profile_level=3
config:_empty_feat=0
config:_arch=5
config:_sample_type=5
config:_cache_policy=12
test_result:init:input_scale_factor=1.1
coll_cache:optimal_rep_storage=0.2
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.8
coll_cache:optimal_local_storage=0.2
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=1
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0
z=299.797
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
test_result:init:feat_nbytes=56862697472
test_result:init:cache_nbytes=11372539392
coll_cache:optimal_rep_storage=0.2
coll_cache:optimal_part_storage=0
coll_cache:optimal_cpu_storage=0.8
coll_cache:optimal_local_storage=0.2
coll_cache:optimal_remote_storage=0
coll_cache:optimal_local_rate=1
coll_cache:optimal_remote_rate=0
coll_cache:optimal_cpu_rate=0
z=299.797
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
test_result:init:cache_nbytes=0
[Train  Worker 3/6] Started with PID 38454(Tesla V100-SXM2-32GB)
[Train  Worker 3] run train for 4 epochs with 156 steps
[Train  Worker 3] Avg Epoch Time 0.5310 | Train Total Time(Profiler) 0.2315 | Copy Time 0.2969
[Train  Worker 5/6] Started with PID 38460(Tesla V100-SXM2-32GB)
[Train  Worker 5] run train for 4 epochs with 156 steps
[Train  Worker 5] Avg Epoch Time 0.5310 | Train Total Time(Profiler) 0.2742 | Copy Time 0.2543
[Train  Worker 0/6] Started with PID 38445(Tesla V100-SXM2-32GB)
[Train  Worker 0] run train for 4 epochs with 156 steps
Epoch 00000 | Epoch Time 1.9633 | Total Train Time(Profiler) 1.6837 | Copy Time 0.2765
Epoch 00001 | Epoch Time 0.5312 | Total Train Time(Profiler) 0.2733 | Copy Time 0.2553
Epoch 00002 | Epoch Time 0.5308 | Total Train Time(Profiler) 0.2726 | Copy Time 0.2554
Epoch 00003 | Epoch Time 0.5308 | Total Train Time(Profiler) 0.2726 | Copy Time 0.2557
[Train  Worker 0] Avg Epoch Time 0.5309 | Train Total Time(Profiler) 0.2728 | Copy Time 0.2555
[Train  Worker 4/6] Started with PID 38457(Tesla V100-SXM2-32GB)
[Train  Worker 4] run train for 4 epochs with 156 steps
[Train  Worker 4] Avg Epoch Time 0.5309 | Train Total Time(Profiler) 0.2322 | Copy Time 0.2962
[Train  Worker 1/6] Started with PID 38448(Tesla V100-SXM2-32GB)
[Train  Worker 1] run train for 4 epochs with 156 steps
[Train  Worker 1] Avg Epoch Time 0.5310 | Train Total Time(Profiler) 0.2291 | Copy Time 0.2992
[Train  Worker 2/6] Started with PID 38451(Tesla V100-SXM2-32GB)
[Train  Worker 2] run train for 4 epochs with 156 steps
[Train  Worker 2] Avg Epoch Time 0.5310 | Train Total Time(Profiler) 0.2292 | Copy Time 0.2991
[Sample Worker 1/2] Started with PID 38443(Tesla V100-SXM2-32GB)
[Sample Worker 1] run sample for 4 epochs with 78 steps
[Sample Worker 1] Avg Sample Total Time 0.5922 | Sampler Total Time(Profiler) 0.5914
    [Step(average) Profiler Level 1 E3 S77]
        L1  sample           0.006104 | send           0.001482
        L1  recv             0.000000 | copy           0.000000 | convert time 0.000000 | train  0.000000
        L1  feature nbytes 0.00 Bytes | label nbytes 0.00 Bytes
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes         1099576 | num samples     1708794
    [Step(average) Profiler Level 2 E3 S77]
        L2  shuffle     0.000491 | core sample  0.002125 | id remap        0.003376
        L2  graph copy  0.000000 | id copy      0.000000 | cache feat copy 0.000000
        L2  last layer sample time 0.000359 | size 72311.816239
    [Step(average) Profiler Level 3 E3 S77]
        L3  khop sample coo  0.001791 | khop sort coo      0.000000 | khop count edge     0.000044 | khop compact edge 0.000248
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.002756 | remap mapnode       0.000000 | remap mapedge     0.000619
        L3  cache get_index  0.000000 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.000000 | cache combine remote 0.000000
        L3  label extract  0.000000
    [Init Profiler Level 1]
        L1  init     7.6399 | sampler init    16.2239 | trainer init 0.0000
    [Init Profiler Level 2]
        L2  load ds        10.3711 | init queue           5.6370
        L2  presample       5.4309 | build interal ds     2.4198
        L2  build cache     0.0000
    [Init Profiler Level 3]
        L3  load dataset: mmap     7.6351 | copy         2.7360
        L3  dist queue: alloc      0.0019 | pin          5.6351 | push     0.0000
        L3  presample: init        0.3711
        L3  presample: sample      1.7967 | copy         0.1135
        L3  presample: count       2.4883 | sort         0.2315
        L3  presample: reset       0.0006 | get rank     0.0243
        L3  internal: cuda ctx     2.1332 | cuda stream     0.2798
[Sample Worker 0/2] Started with PID 38442(Tesla V100-SXM2-32GB)
[Sample Worker 0] run sample for 4 epochs with 78 steps
[Sample Worker 0] Avg Sample Total Time 0.5939 | Sampler Total Time(Profiler) 0.5917
test_result:sample_time=0.4761
test_result:get_cache_miss_index_time=0.0000
test_result:enqueue_samples_time=0.1156
test_result:epoch_time:sample_total=0.5939
[CUDA] cuda0: usage: 14.65 GB
[SAM] cuda0 data alloc        : 0.00 Bytes
[SAM] cuda0 workspace         : 1.18 GB
[SAM] cuda0 workspace reserve : 603.26 MB
[SAM] cuda0 total             : 1.18 GB
    [Step(average) Profiler Level 1 E3 S155]
        L1  sample           0.000000 | send           0.000000
        L1  recv             0.002621 | copy           0.010903 | convert time 0.000415 | train  0.009004
        L1  feature nbytes  536.87 MB | label nbytes   62.50 KB
        L1  id nbytes      0.00 Bytes | graph nbytes 0.00 Bytes
        L1  miss nbytes    0.00 Bytes | remote nbytes 0.00 Bytes
        L1  num nodes               0 | num samples           0
    [Step(average) Profiler Level 2 E3 S155]
        L2  shuffle     0.000000 | core sample  0.000000 | id remap        0.000000
        L2  graph copy  0.000004 | id copy      0.000000 | cache feat copy 0.008278
        L2  last layer sample time 0.000000 | size 0.000000
    [Step(average) Profiler Level 3 E3 S155]
        L3  khop sample coo  0.000000 | khop sort coo      0.000000 | khop count edge     0.000000 | khop compact edge 0.000000
        L3  walk sample coo  0.000000 | walk topk total    0.000000 | walk topk step1     0.000000 | walk topk step2   0.000000
        L3  walk topk step3  0.000000 | walk topk step4    0.000000 | walk topk step5     0.000000
        L3  walk topk step6  0.000000 | walk topk step7    0.000000
        L3  remap unique     0.000000 | remap populate     0.000000 | remap mapnode       0.000000 | remap mapedge     0.000000
        L3  cache get_index  0.000000 | cache copy_index   0.000000 | cache extract_miss  0.000000
        L3  cache copy_miss  0.000000 | cache combine_miss 0.000000 | cache combine cache 0.007707 | cache combine remote 0.000000
        L3  label extract  0.000563
    [Init Profiler Level 1]
        L1  init     7.6399 | sampler init     0.0000 | trainer init 44.5316
    [Init Profiler Level 2]
        L2  load ds         7.6351 | init queue           5.4934
        L2  presample       0.0000 | build interal ds     2.0288
        L2  build cache    37.0020
    [Init Profiler Level 3]
        L3  load dataset: mmap     7.6351 | copy         0.0000
        L3  dist queue: alloc      0.0019 | pin          5.4915 | push     0.0000
        L3  presample: init        0.0000
        L3  presample: sample      0.0000 | copy         0.0000
        L3  presample: count       0.0000 | sort         0.0000
        L3  presample: reset       0.0000 | get rank     0.0000
        L3  internal: cuda ctx     2.0287 | cuda stream     0.0001
|===========================================================================|
|                  PyTorch CUDA memory summary, device ID 0                 |
|---------------------------------------------------------------------------|
|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |
|===========================================================================|
|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |
|---------------------------------------------------------------------------|
| Allocated memory      |   22886 KB |  402244 KB |  145048 MB |  145025 MB |
|       from large pool |   18210 KB |  398867 KB |  143970 MB |  143953 MB |
|       from small pool |    4676 KB |    7110 KB |    1077 MB |    1072 MB |
|---------------------------------------------------------------------------|
| Active memory         |   22886 KB |  402244 KB |  145048 MB |  145025 MB |
|       from large pool |   18210 KB |  398867 KB |  143970 MB |  143953 MB |
|       from small pool |    4676 KB |    7110 KB |    1077 MB |    1072 MB |
|---------------------------------------------------------------------------|
| GPU reserved memory   |  577536 KB |  577536 KB |  577536 KB |       0 B  |
|       from large pool |  569344 KB |  569344 KB |  569344 KB |       0 B  |
|       from small pool |    8192 KB |    8192 KB |    8192 KB |       0 B  |
|---------------------------------------------------------------------------|
| Non-releasable memory |   24217 KB |  368931 KB |  170012 MB |  169989 MB |
|       from large pool |   22750 KB |  367112 KB |  168777 MB |  168755 MB |
|       from small pool |    1467 KB |    3610 KB |    1235 MB |    1234 MB |
|---------------------------------------------------------------------------|
| Allocations           |      38    |      51    |   11583    |   11545    |
|       from large pool |       3    |      14    |    4576    |    4573    |
|       from small pool |      35    |      39    |    7007    |    6972    |
|---------------------------------------------------------------------------|
| Active allocs         |      39    |      51    |   11583    |   11544    |
|       from large pool |       3    |      14    |    4576    |    4573    |
|       from small pool |      36    |      39    |    7007    |    6971    |
|---------------------------------------------------------------------------|
| GPU reserved segments |      13    |      13    |      13    |       0    |
|       from large pool |       9    |       9    |       9    |       0    |
|       from small pool |       4    |       4    |       4    |       0    |
|---------------------------------------------------------------------------|
| Non-releasable allocs |      14    |      24    |    5447    |    5433    |
|       from large pool |       4    |      12    |    2625    |    2621    |
|       from small pool |      10    |      14    |    2822    |    2812    |
|---------------------------------------------------------------------------|
| Oversize allocations  |       0    |       0    |       0    |       0    |
|---------------------------------------------------------------------------|
| Oversize GPU segments |       0    |       0    |       0    |       0    |
|===========================================================================|

test_result:epoch_time:copy_time=0.2555
test_result:convert_time=0.0109
test_result:train_time=0.2619
test_result:epoch_time:train_total=0.2728
test_result:cache_percentage=0.2000
test_result:cache_hit_rate=1.0000
test_result:run_time=5.9482

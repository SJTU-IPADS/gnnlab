[2022-12-05 17:14:03.255735: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 13.46 GB
[2022-12-05 17:14:03.255815: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 13.46 GB done
[2022-12-05 17:14:07.429323: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 62.57 GB
[2022-12-05 17:14:07.429433: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 62.57 GB done
[2022-12-05 17:14:07.429499: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 13.46 GB
[2022-12-05 17:14:08.389170: E /samgraph/samgraph/common/engine.cc:272] Train set size 30.58 MB
[2022-12-05 17:14:08.389536: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-05 17:14:08.389559: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-05 17:14:09.682332: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-05 17:14:09.703764: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-05 17:14:09.761092: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[5] initializing...
[2022-12-05 17:14:09.815943: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-05 17:14:09.846406: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[4] initializing...
[2022-12-05 17:14:09.922658: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[3] initializing...
[2022-12-05 17:14:11.199022: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-05 17:14:11.216974: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-05 17:14:11.221294: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-05 17:14:11.224626: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[4] pin memory queue...
[2022-12-05 17:14:11.228825: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[3] pin memory queue...
[2022-12-05 17:14:11.234004: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[5] pin memory queue...
[2022-12-05 17:14:31.167744: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.168192: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.168712: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.168911: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[5] register host memory...
[2022-12-05 17:14:31.169002: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[4] register host memory...
[2022-12-05 17:14:31.169112: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.169622: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[0] register host memory...
[2022-12-05 17:14:31.169873: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-05 17:14:31.190646: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.191099: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[3] register host memory...
[2022-12-05 17:14:31.215194: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.215359: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-05 17:14:31.361247: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.414089: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 17:14:31.414206: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 30.58 MB
[2022-12-05 17:14:31.423387: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 250.28 MB
[2022-12-05 17:14:31.469473: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 13.46 GB
[2022-12-05 17:14:33.341286: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 17:14:33.350460: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 19.12 MB
[2022-12-05 17:14:33.350829: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 256.00 MB
[2022-12-05 17:14:33.350970: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 26.18 MB
[2022-12-05 17:14:33.351325: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 28.56 MB
[2022-12-05 17:14:33.351788: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 17:14:33.360483: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-05 17:14:33.360522: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 17:14:33.369521: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 38.23 MB
[2022-12-05 17:14:33.369547: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-05 17:14:33.369558: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 500.55 MB
[2022-12-05 17:14:33.450001: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-05 17:14:33.557605: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.21 MB
[2022-12-05 17:14:33.557773: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.21 MB
[2022-12-05 17:14:33.557906: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.21 MB
[2022-12-05 17:14:33.558026: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.21 MB
[2022-12-05 17:14:33.562671: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 25.65 MB
[2022-12-05 17:14:33.563302: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 20.53 MB
[2022-12-05 17:15:06.184264: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 6.45812 on sample, 0.726689 on copy, 25.5361 on count
[2022-12-05 17:15:06.184355: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-05 17:15:39.234395: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 12.9535 on sample, 1.45398 on copy, 51.3491 on count
[2022-12-05 17:15:39.234540: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 4330040, min_num_inputs = 4273626
[2022-12-05 17:15:39.359039: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.124413 on sort freq.
[2022-12-05 17:15:39.460373: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[[[[[2022-12-05 17:15:392022-12-05 17:15:392022-12-05 17:15:392022-12-05 17:15:392022-12-05 17:15:392022-12-05 17:15:39......472556472554472558472554472554472553: : : : : : WWWWWW      /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc::::::711711711711711711] ] ] ] ] ] Trainer[5] building cache...Trainer[3] building cache...Trainer[0] building cache...Trainer[2] building cache...Trainer[1] building cache...Trainer[4] building cache...





[[2022-12-05 17:15:392022-12-05 17:15:39.[.4739942022-12-05 17:15:39473997: .: E474007E :  /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.ccE/samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc: :134/samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc134] :] using concurrent impl MPS134using concurrent impl MPS
] 
using concurrent impl MPS
[2022-12-05 17:15:39.474051: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 17:15:39.474140: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 17:15:39.475174: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.475204: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 17:15:39.475215: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 17:15:39.475589: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.475610[: 2022-12-05 17:15:39E. 475608/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc: :E197 ] /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.ccremote time is 10.8824:
196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.475628: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] [cpu time is 41.11112022-12-05 17:15:39
.475635: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 17:15:39.475648: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 17:15:39.475788: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.475812: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 17:15:39.475823: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 17:15:39.475946: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.475966: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 17:15:39.475977: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 17:15:39.491976: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 17:15:39.493105: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 17:15:39.493128: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 17:15:39.493138: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 17:15:55.229624: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:115] solver created. now build & solve
[2022-12-05 17:15:55.271129: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:120] solver built. now solve
[2022-12-05 17:15:55.271179: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 3280418
[2022-12-05 17:15:55.879132: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:124] solver solved
[2022-12-05 17:15:55.879217: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:187] 0 solved master
[2022-12-05 17:15:55.879240: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 0 solved
[2022-12-05 17:15:55.879251: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 0 thread 0 initing device 0
[2022-12-05 17:15:55.886179: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 4 solved
[2022-12-05 17:15:55.886230: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 4 thread 4 initing device 4
[2022-12-05 17:15:55.886537: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 5 solved
[2022-12-05 17:15:55.886574: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 5 thread 5 initing device 5
[2022-12-05 17:15:55.886601: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 3 solved
[2022-12-05 17:15:55.886626: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 3 thread 3 initing device 3
[[2022-12-05 17:15:552022-12-05 17:15:55..890108890108: : EE  /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc::194194] ] 2 solved
1 solved
[2022-12-05 17:15:55.[8901502022-12-05 17:15:55: .E890152 : /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.ccE: 197/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc] :worker 2 thread 2 initing device 2197
] worker 1 thread 1 initing device 1
[2022-12-05 17:15:56.222811: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.335935 secs 
[2022-12-05 17:15:56.223033: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.335481 secs 
[2022-12-05 17:15:56.223448: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.33259 secs 
[2022-12-05 17:15:56.226117: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.346112 secs 
[2022-12-05 17:15:56.226474: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.338836 secs 
[2022-12-05 17:15:56.226675: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 3280418 / 65608366 nodes ( 5.00 %~5.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 62327948 / 65608366 nodes ( 95.00 %) | 3.13 GB | 0.335793 secs 
[2022-12-05 17:15:56.226713: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 4.78 GB
[2022-12-05 17:15:57.354805: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 5.21 GB
[2022-12-05 17:15:57.355564: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 5.21 GB
[2022-12-05 17:15:57.357539: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 5.21 GB
[2022-12-05 17:15:58.415238: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 5.63 GB
[2022-12-05 17:15:58.415468: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 5.63 GB
[2022-12-05 17:15:58.416472: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 5.63 GB
[2022-12-05 17:15:59.559377: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 6.06 GB
[2022-12-05 17:15:59.561942: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 6.06 GB
[2022-12-05 17:15:59.564432: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 6.06 GB
[2022-12-05 17:16:00.898359: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 6.49 GB
[2022-12-05 17:16:00.898620: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 6.49 GB
[2022-12-05 17:16:00.899538: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 6.49 GB
[2022-12-05 17:16:02.286957: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 6.92 GB
[2022-12-05 17:16:02.287056: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 6.92 GB
[2022-12-05 17:16:02.287301: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 6.92 GB
[2022-12-05 17:16:03.524958: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 7.67 GB
[2022-12-05 17:16:03.525160: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 7.67 GB
[2022-12-05 17:16:03.525390: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 7.67 GB
[2022-12-05 17:16:04.463185: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 8.05 GB
[2022-12-05 17:16:04.463347: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 8.05 GB
[2022-12-05 17:16:12.826688: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.17 MB
[2022-12-05 17:16:12.828131: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 28.14 MB
[2022-12-05 17:16:12.829079: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 28.14 MB
[2022-12-05 17:16:12.840456: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 4.43 GB
[2022-12-05 17:16:12.841137: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.17 MB
[2022-12-05 17:16:12.841720: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 44.33 MB
[2022-12-05 17:16:12.842443: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.17 MB
[2022-12-05 17:16:12.842856: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 44.33 MB
[2022-12-05 17:16:14.409086: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 20.48 MB
[2022-12-05 17:16:14.410292: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 25.61 MB
[2022-12-05 17:16:14.411347: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 25.61 MB
[2022-12-05 17:16:14.434102: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 4.43 GB
[2022-12-05 17:16:14.434813: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 20.48 MB
[2022-12-05 17:16:14.435522: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 40.96 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

[2022-12-05 16:22:32.117773: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 12.03 GB
[2022-12-05 16:22:32.117840: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 12.03 GB done
[2022-12-05 16:22:36.224474: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 52.96 GB
[2022-12-05 16:22:36.224542: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 52.96 GB done
[2022-12-05 16:22:36.224586: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.03 GB
[2022-12-05 16:22:37.103993: E /samgraph/samgraph/common/engine.cc:272] Train set size 30.58 MB
[2022-12-05 16:22:37.104342: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-05 16:22:37.104364: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-05 16:22:40.163722: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-05 16:22:40.246933: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-05 16:22:40.277437: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[4] initializing...
[2022-12-05 16:22:40.303358: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[5] initializing...
[2022-12-05 16:22:40.403436: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[3] initializing...
[2022-12-05 16:22:40.454180: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-05 16:22:42.974433: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-05 16:22:43.  4799: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-05 16:22:43. 12688: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[5] pin memory queue...
[2022-12-05 16:22:43. 12899: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[4] pin memory queue...
[2022-12-05 16:22:43. 33863: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[3] pin memory queue...
[2022-12-05 16:22:43. 35040: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-05 16:23:03. 34841: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 35517: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[5] register host memory...
[2022-12-05 16:23:03. 35933: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 36805: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 37218: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-05 16:23:03. 37809: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[4] register host memory...
[2022-12-05 16:23:03. 38876: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 39617: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-05 16:23:03. 57649: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 58159: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[0] register host memory...
[2022-12-05 16:23:03. 80399: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03. 80569: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[3] register host memory...
[2022-12-05 16:23:03.237251: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03.237384: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 30.58 MB
[2022-12-05 16:23:03.246919: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 423.66 MB
[2022-12-05 16:23:03.265127: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on A100
[2022-12-05 16:23:03.316917: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 12.03 GB
[2022-12-05 16:23:05. 66849: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 16:23:05. 77021: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 19.12 MB
[2022-12-05 16:23:05. 77661: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 256.00 MB
[2022-12-05 16:23:05. 77895: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 26.18 MB
[2022-12-05 16:23:05. 78370: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 28.56 MB
[2022-12-05 16:23:05. 78848: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 16:23:05. 88001: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-05 16:23:05. 88038: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 38.23 MB
[2022-12-05 16:23:05. 97311: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 38.23 MB
[2022-12-05 16:23:05. 97337: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-05 16:23:05. 97349: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 847.32 MB
[2022-12-05 16:23:05.242546: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-05 16:23:05.349937: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.23 MB
[2022-12-05 16:23:05.350099: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.23 MB
[2022-12-05 16:23:05.350229: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.23 MB
[2022-12-05 16:23:05.350349: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 27.23 MB
[2022-12-05 16:23:05.354409: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[6] alloc cuda memory 24.34 MB
[2022-12-05 16:23:05.355011: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 20.41 MB
[2022-12-05 16:23:37.598777: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 5.72652 on sample, 0.724992 on copy, 25.8912 on count
[2022-12-05 16:23:37.598862: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-05 16:24:10.227040: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 11.4916 on sample, 1.44755 on copy, 52.019 on count
[2022-12-05 16:24:10.227134: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 4312853, min_num_inputs = 4249875
[2022-12-05 16:24:10.384471: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.157266 on sort freq.
[2022-12-05 16:24:10.564366: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[[2022-12-05 16:24:102022-12-05 16:24:102022-12-05 16:24:10...582635582634582634: : : W[WW[[  2022-12-05 16:24:10 2022-12-05 16:24:10/samgraph/samgraph/common/dist/dist_engine.cc2022-12-05 16:24:10/samgraph/samgraph/common/dist/dist_engine.cc./samgraph/samgraph/common/dist/dist_engine.cc.:.:582652:582652711582652711: 711: ] : ] W] WTrainer[2] building cache...WTrainer[5] building cache... Trainer[4] building cache... 
 
/samgraph/samgraph/common/dist/dist_engine.cc
/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:::711711711] ] ] Trainer[0] building cache...Trainer[3] building cache...Trainer[1] building cache...


[2022-12-05 16:24:10.584456: [E2022-12-05 16:24:10 ./samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc584466:[: 1342022-12-05 16:24:10E] . using concurrent impl MPS584471/samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc
: :E134 ] /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.ccusing concurrent impl MPS:
134] using concurrent impl MPS
[2022-12-05 16:24:10.584514: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:24:10.584537: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:24:10.585832: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 16:24:10.585860: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 16:24:10.585871: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 16:24:10.585917: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 16:24:10.585927: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8[
2022-12-05 16:24:10.585939: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 16:24:10.585948: E[ 2022-12-05 16:24:10/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc.:585951197: ] Eremote time is 10.8824 
/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111[
2022-12-05 16:24:10.585965: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 16:24:10.586311: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 16:24:10.586343: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 16:24:10.586354: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 16:24:10.586438: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 16:24:10.586460: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 16:24:10.586470: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 16:24:10.592181: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:24:10.593217: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 6X NVIDIA A100-SXM4-80GB out of 8
[2022-12-05 16:24:10.593239: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 10.8824
[2022-12-05 16:24:10.593250: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 41.1111
[2022-12-05 16:24:23.982329: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:115] solver created. now build & solve
[2022-12-05 16:24:24. 37589: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:120] solver built. now solve
[2022-12-05 16:24:24. 37622: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 16658993
[2022-12-05 16:24:24.932603: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:124] solver solved
[2022-12-05 16:24:24.932695: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:187] 0 solved master
[2022-12-05 16:24:24.932716: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 0 solved
[2022-12-05 16:24:24.932726: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 0 thread 0 initing device 0
[2022-12-05 16:24:24.948627: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 1 solved
[2022-12-05 16:24:24.948686: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 1 thread 1 initing device 1
[[[2022-12-05 16:24:242022-12-05 16:24:24.2022-12-05 16:24:24.950669.950670: 950671: E: E E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194:194] 194] 4 solved] 2 solved
3 solved

[2022-12-05 16:24:24.[[9507222022-12-05 16:24:242022-12-05 16:24:24: ..E950723950723 : : /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.ccEE:  197/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc/samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc] ::worker 4 thread 4 initing device 4197197
] ] worker 3 thread 3 initing device 3worker 2 thread 2 initing device 2

[2022-12-05 16:24:24.953872: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 5 solved
[2022-12-05 16:24:24.953919: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 5 thread 5 initing device 5
[2022-12-05 16:24:25.733856: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.780824 secs 
[2022-12-05 16:24:25.734401: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.783025 secs 
[2022-12-05 16:24:25.735122: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.784672 secs 
[2022-12-05 16:24:25.736204: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.783146 secs 
[2022-12-05 16:24:25.738440: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.783755 secs 
[2022-12-05 16:24:25.739447: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 16658993 / 111059956 nodes ( 15.00 %~15.00 %) | remote 0 / 111059956 nodes ( 0.00 %) | cpu 94400963 / 111059956 nodes ( 85.00 %) | 7.94 GB | 0.805939 secs 
[2022-12-05 16:24:25.740081: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 9.91 GB
[2022-12-05 16:24:26.854907: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 10.34 GB
[2022-12-05 16:24:26.854983: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 10.34 GB
[2022-12-05 16:24:26.855138: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 10.34 GB
[2022-12-05 16:24:27.767605: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 10.77 GB
[2022-12-05 16:24:27.767680: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 10.77 GB
[2022-12-05 16:24:27.767834: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 10.77 GB
[2022-12-05 16:24:28.808131: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 11.19 GB
[2022-12-05 16:24:28.808305: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 11.19 GB
[2022-12-05 16:24:28.808470: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 11.19 GB
[2022-12-05 16:24:29.919538: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 11.62 GB
[2022-12-05 16:24:29.919627: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 11.62 GB
[2022-12-05 16:24:29.919850: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 11.62 GB
[2022-12-05 16:24:31. 77138: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 12.05 GB
[2022-12-05 16:24:31. 77291: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 12.05 GB
[2022-12-05 16:24:31. 79831: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 12.05 GB
[2022-12-05 16:24:32.223702: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 12.80 GB
[2022-12-05 16:24:32.224194: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 12.80 GB
[2022-12-05 16:24:32.225872: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 12.80 GB
[2022-12-05 16:24:33.399868: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 13.18 GB
[2022-12-05 16:24:33.399965: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 13.18 GB
[2022-12-05 16:24:41.454150: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.27 MB
[2022-12-05 16:24:41.455363: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 26.73 MB
[2022-12-05 16:24:41.456580: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 26.73 MB
[2022-12-05 16:24:41.462588: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 2.23 GB
[2022-12-05 16:24:41.466407: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.27 MB
[2022-12-05 16:24:41.467134: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 44.54 MB
[2022-12-05 16:24:41.467739: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 22.27 MB
[2022-12-05 16:24:41.468252: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 44.54 MB
[2022-12-05 16:24:42.838242: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 20.41 MB
[2022-12-05 16:24:42.839463: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 24.32 MB
[2022-12-05 16:24:42.840520: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 24.32 MB
[2022-12-05 16:24:42.854307: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 2.23 GB
[2022-12-05 16:24:42.855084: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 20.41 MB
[2022-12-05 16:24:42.855768: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 40.82 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

[2022-12-09 10:19:50.990443: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 12.87 GB
[2022-12-09 10:19:50.990556: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 12.87 GB done
[2022-12-09 10:19:56.299589: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 48.00 GB
[2022-12-09 10:19:56.299706: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 48.00 GB done
[2022-12-09 10:19:56.299749: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 1.82 GB
[2022-12-09 10:19:56.299782: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 1.82 GB done
[2022-12-09 10:19:56.299842: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.87 GB
[2022-12-09 10:19:57.129004: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-09 10:19:57.129755: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-09 10:19:57.129794: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-09 10:19:57.338038: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-09 10:19:57.339367: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-09 10:19:57.340368: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-09 10:19:58.894883: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-09 10:19:58.899803: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-09 10:19:58.900081: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-09 10:20:23.180195[: 2022-12-09 10:20:23E. 180230/samgraph/samgraph/common/dist/dist_engine.cc: :E85 ] /samgraph/samgraph/common/dist/dist_engine.ccRunning on V100:
85] Running on V100
[2022-12-09 10:20:23.180753: [W2022-12-09 10:20:23 ./samgraph/samgraph/common/dist/dist_engine.cc180769:: 701W]  Trainer[2] register host memory.../samgraph/samgraph/common/dist/dist_engine.cc
:701] Trainer[0] register host memory...
[2022-12-09 10:20:23.198829: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-09 10:20:23.198904: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-09 10:20:23.426007: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-09 10:20:23.431660: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 931.40 MB
[2022-12-09 10:20:23.559325: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 12.87 GB
[2022-12-09 10:20:25.135180: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-09 10:20:25.140479: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-09 10:20:25.145452: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-09 10:20:25.145499: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 1.82 GB
[2022-12-09 10:20:25.784221: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-09 10:20:33.495881: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 3.68054 on sample, 0.303599 on copy, 3.71555 on count
[2022-12-09 10:20:33.496029: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-09 10:20:41.328825: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 7.36126 on sample, 0.604996 on copy, 7.55436 on count
[2022-12-09 10:20:41.328950: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 975227, min_num_inputs = 930902
[2022-12-09 10:20:41.932947: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.603898 on sort freq.
[2022-12-09 10:20:42.613256: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[2022-12-09 10:20:42[.2022-12-09 10:20:426764912022-12-09 10:20:42.: .676494W: 676501 W: /samgraph/samgraph/common/dist/dist_engine.cc W:/samgraph/samgraph/common/dist/dist_engine.cc 711/samgraph/samgraph/common/dist/dist_engine.cc:] :711Trainer[0] building cache...711] 
] Trainer[2] building cache...Trainer[1] building cache...

[2022-12-09 10:20:42.678209: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:188] assigning 16 to cpu
[2022-12-09 10:20:42.678261: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:204] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-09 10:20:42.678301: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:205] remote time is 8.68421
[2022-12-09 10:20:42.678329: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:206] cpu time is 30
[2022-12-09 10:20:42.679119: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:188] assigning 16 to cpu
[2022-12-09 10:20:42.679197: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:204] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-09 10:20:42.679253: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:205] remote time is 8.68421
[2022-12-09 10:20:42[.2022-12-09 10:20:42679298.: 679285E:  E/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc :/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc206:] 188cpu time is 30] 
assigning 16 to cpu
[2022-12-09 10:20:42.679412: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:204] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-09 10:20:42.679490: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:205] remote time is 8.68421
[2022-12-09 10:20:42.679554: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:206] cpu time is 30
[2022-12-09 10:21:07.933516: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:118] solver created. now build & solve
[2022-12-09 10:21:08. 35480: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:123] solver built. now solve
[2022-12-09 10:21:08. 35530: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 4883209
[2022-12-09 10:21:09.441084: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:127] solver solved
[2022-12-09 10:21:09.441193: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:195] 0 solved master
[2022-12-09 10:21:09.441235: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 0 solved
[2022-12-09 10:21:09.441264: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 0 thread 0 initing device 0
[2022-12-09 10:21:09.484614: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 2 solved
[2022-12-09 10:21:09.484684: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 2 thread 2 initing device 2
[2022-12-09 10:21:09.485157: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:202] 1 solved
[2022-12-09 10:21:09.485225: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:205] worker 1 thread 1 initing device 1
[2022-12-09 10:21:09.626546: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1634] using empty feat=25
[2022-12-09 10:21:09.694176: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1634] using empty feat=25
[2022-12-09 10:21:09.770456: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1634] using empty feat=25
[2022-12-09 10:21:10.405366: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 6.99 GB | 0.919182 secs 
[2022-12-09 10:21:10.405508: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 6.99 GB | 0.963119 secs 
[2022-12-09 10:21:10.405571: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1744] Collaborative GPU cache (policy: rep_cache) | local 4883209 / 244160499 nodes ( 2.00 %~2.00 %) | remote 0 / 244160499 nodes ( 0.00 %) | cpu 239277290 / 244160499 nodes ( 98.00 %) | 6.99 GB | 0.919227 secs 
[2022-12-09 10:21:16.968848: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.50 GB
[2022-12-09 10:21:18.607127: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.50 GB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

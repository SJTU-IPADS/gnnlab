[2022-12-05 16:13:12.568262: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 12.03 GB
[2022-12-05 16:13:12.568366: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 12.03 GB done
[2022-12-05 16:13:17.702323: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 52.96 GB
[2022-12-05 16:13:17.702432: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 52.96 GB done
[2022-12-05 16:13:17.702538: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 12.03 GB
[2022-12-05 16:13:18.528359: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-05 16:13:18.529152: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-05 16:13:18.529197: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-05 16:13:18.721905: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-05 16:13:18.767944: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-05 16:13:18.786218: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-05 16:13:20.186712: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-05 16:13:20.187309: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-05 16:13:20.211884: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-05 16:13:43.513436: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:13:43.513472: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:13:43.513858: W [/samgraph/samgraph/common/dist/dist_engine.cc2022-12-05 16:13:43:.701513875] : Trainer[0] register host memory...W
 /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[2] register host memory...
[2022-12-05 16:13:43.537186: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:13:43.537272: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[1] register host memory...
[2022-12-05 16:13:43.755438: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 16:13:43.760585: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 423.66 MB
[2022-12-05 16:13:43.875175: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 12.03 GB
[2022-12-05 16:13:46.858386: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-05 16:13:46.863844: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-05 16:13:46.868942: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-05 16:13:46.868989: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 847.32 MB
[2022-12-05 16:13:47.165058: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-05 16:13:56.803576: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 4.6151 on sample, 0.365826 on copy, 4.64507 on count
[2022-12-05 16:13:56.803696: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-05 16:14:06.325136: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 9.17612 on sample, 0.72867 on copy, 9.23124 on count
[2022-12-05 16:14:06.325251: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1173868, min_num_inputs = 1139450
[2022-12-05 16:14:06.627417: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.302071 on sort freq.
[2022-12-05 16:14:06.970173: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[2022-12-05 16:14:06.995902[: [2022-12-05 16:14:06W2022-12-05 16:14:06. .995915/samgraph/samgraph/common/dist/dist_engine.cc995927: :: W711W ]  /samgraph/samgraph/common/dist/dist_engine.ccTrainer[0] building cache.../samgraph/samgraph/common/dist/dist_engine.cc:
:711711] ] Trainer[1] building cache...Trainer[2] building cache...

[2022-12-05 16:14:06.998007: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:14:06.998141: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:14:06.998425: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 16:14:06[2022-12-05 16:14:06.998931: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 16:14:06.999044: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 8.68421
[2022-12-05 16:14:06.999121: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
.998473: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 8.68421
[2022-12-05 16:14:07.   711: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 16:14:07.  3445: E /samgraph/3rdparty/collcachelib/coll_cache_lib/run_config.cc:134] using concurrent impl MPS
[2022-12-05 16:14:07.  4059: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 16:14:07.  4162: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 8.68421
[2022-12-05 16:14:07.  4240: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 16:14:22.655386: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:115] solver created. now build & solve
[2022-12-05 16:14:22.703251: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:120] solver built. now solve
block 0 storage is 00000001
	access is	0	0	0	
block 1 storage is 00000010
	access is	1	1	1	
block 2 storage is 00000100
	access is	2	2	2	
block 3 storage is 00000000
	access is	3	3	3	
[2022-12-05 16:14:23.195500: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:124] solver solved
[2022-12-05 16:14:23.195561: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:187] 0 solved master
[2022-12-05 16:14:23.195610: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 0 solved
[2022-12-05 16:14:23.195638: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 0 thread 0 initing device 0
[2022-12-05 16:14:23.196915: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1762] Building Coll Cache with ... num gpu device is 3
[2022-12-05 16:14:23.215476: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 1 solved
[2022-12-05 16:14:23.215542: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 1 thread 1 initing device 1
[2022-12-05 16:14:23.215568: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 2 solved
[2022-12-05 16:14:23.215633: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 2 thread 2 initing device 2
[2022-12-05 16:14:23.218245: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1762] Building Coll Cache with ... num gpu device is 3
[2022-12-05 16:14:23.220056: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1762] Building Coll Cache with ... num gpu device is 3
[2022-12-05 16:14:23.308304: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 50.84 MB
[[[2022-12-05 16:14:232022-12-05 16:14:232022-12-05 16:14:23...910183910183910183: : : EEE   /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu/samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu/samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:::187118711871] ] ] Device 0 init p2p of link 1Device 1 init p2p of link 2Device 2 init p2p of link 0


[2022-12-05 16:14:23.920306: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1871] Device 0 init p2p of link 2
[2022-12-05 16:14:23.920411: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1871] Device 2 init p2p of link 1
[2022-12-05 16:14:23.920448: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1871] Device 1 init p2p of link 0
[2022-12-05 16:14:23.930086: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1900] Asymm Coll cache (policy: clique_part) | local 13327194 / 111059956 nodes ( 12.00 %~12.00 %) | remote 26654388 / 111059956 nodes ( 24.00 %) | cpu 71078374 / 111059956 nodes ( 64.00 %) | 6.36 GB | 0.73313 secs 
[2022-12-05 16:14:23.930752: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1900] Asymm Coll cache (policy: clique_part) | local 13327194 / 111059956 nodes ( 12.00 %~12.00 %) | remote 26654388 / 111059956 nodes ( 24.00 %) | cpu 71078374 / 111059956 nodes ( 64.00 %) | 6.36 GB | 0.710646 secs 
[2022-12-05 16:14:23.931244: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1900] Asymm Coll cache (policy: clique_part) | local 13327194 / 111059956 nodes ( 12.00 %~12.00 %) | remote 26654388 / 111059956 nodes ( 24.00 %) | cpu 71078374 / 111059956 nodes ( 64.00 %) | 6.36 GB | 0.71295 secs 
[2022-12-05 16:14:23.931263: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 8.12 GB
[2022-12-05 16:14:25.193632: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 8.61 GB
[2022-12-05 16:14:25.193737: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 8.61 GB
[2022-12-05 16:14:25.193993: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 8.61 GB
[2022-12-05 16:14:26.303762: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 9.10 GB
[2022-12-05 16:14:26.303869: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 9.10 GB
[2022-12-05 16:14:26.304252: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 9.10 GB
[2022-12-05 16:14:27.450963: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 9.74 GB
[2022-12-05 16:14:27.451069: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 9.74 GB
[2022-12-05 16:14:27.451279: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2004] before create ctx, mem is 9.74 GB
[2022-12-05 16:14:28.592358: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2010] after create ctx, mem is 10.11 GB
[2022-12-05 16:14:28.592467: W /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:2017] after create stream, mem is 10.11 GB
[2022-12-05 16:14:35.519477: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 615.62 MB
[2022-12-05 16:14:35.519959: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 12.03 MB
[2022-12-05 16:14:35.520368: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 12.03 MB
[2022-12-05 16:14:36.661471: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 615.62 MB
[2022-12-05 16:14:36.662632: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 10.99 MB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")

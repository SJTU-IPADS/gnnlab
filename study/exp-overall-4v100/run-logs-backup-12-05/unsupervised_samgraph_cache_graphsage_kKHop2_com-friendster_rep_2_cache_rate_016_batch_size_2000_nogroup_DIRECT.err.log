[2022-12-05 17:38:10.509418: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 13.46 GB
[2022-12-05 17:38:10.509521: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 13.46 GB done
[2022-12-05 17:38:16.186862: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 62.57 GB
[2022-12-05 17:38:16.186985: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 62.57 GB done
[2022-12-05 17:38:16.187074: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 13.46 GB
[2022-12-05 17:38:17.  6462: E /samgraph/samgraph/common/engine.cc:272] Train set size 7.64 MB
[2022-12-05 17:38:17.  7182: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:92] mmap allocating space 68.50 GB
[2022-12-05 17:38:17.  7220: W /samgraph/samgraph/common/cpu/mmap_cpu_device.cc:97] mmap allocating space 68.50 GB done
/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.12) or chardet (3.0.4) doesn't match a supported version!
  warnings.warn("urllib3 ({}) or chardet ({}) doesn't match a supported "
[2022-12-05 17:38:17.168800: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[0] initializing...
[2022-12-05 17:38:17.286289: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[1] initializing...
[2022-12-05 17:38:17.288160: W /samgraph/samgraph/common/dist/dist_engine.cc:662] Trainer[2] initializing...
[2022-12-05 17:38:18.699125: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[0] pin memory queue...
[2022-12-05 17:38:18.736696: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[1] pin memory queue...
[2022-12-05 17:38:18.738882: W /samgraph/samgraph/common/dist/dist_engine.cc:666] Trainer[2] pin memory queue...
[2022-12-05 17:38:41.362458: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 17:38:41.362855: W /samgraph/samgraph/common/dist/dist_engine.cc:701] Trainer[0] register host memory...
[2022-12-05 17:38:41.[3628852022-12-05 17:38:41: .E362915 : /samgraph/samgraph/common/dist/dist_engine.ccE: 85/samgraph/samgraph/common/dist/dist_engine.cc] :Running on V10085
] Running on V100
[2022-12-05 17:38:41.363250[: 2022-12-05 17:38:41W. 363262/samgraph/samgraph/common/dist/dist_engine.cc: :W701 ] /samgraph/samgraph/common/dist/dist_engine.ccTrainer[2] register host memory...:
701] Trainer[1] register host memory...
[2022-12-05 17:38:41.612959: E /samgraph/samgraph/common/dist/dist_engine.cc:85] Running on V100
[2022-12-05 17:38:41.618200: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 250.28 MB
[2022-12-05 17:38:41.693136: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 13.46 GB
[2022-12-05 17:38:45. 45803: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[3] alloc cuda memory 64.00 MB
[2022-12-05 17:38:45. 51470: E /samgraph/samgraph/common/dist/pre_sampler.cc:41] Dist Presampler making shuffler...
[2022-12-05 17:38:45. 56576: E /samgraph/samgraph/common/dist/pre_sampler.cc:44] Dist Presampler making shuffler...Done
[2022-12-05 17:38:45. 56625: W /samgraph/samgraph/common/cpu/cpu_device.cc:39] WORKER[0] alloc host memory 500.55 MB
[2022-12-05 17:38:45.232230: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 0
[2022-12-05 17:38:56. 42873: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 5.51407 on sample, 0.398459 on copy, 4.88608 on count
[2022-12-05 17:38:56. 42994: E /samgraph/samgraph/common/dist/pre_sampler.cc:85] Dist Presampler doing presample epoch 1
[2022-12-05 17:39:06.820171: E /samgraph/samgraph/common/dist/pre_sampler.cc:129] presample spend 10.9785 on sample, 0.794206 on copy, 9.79146 on count
[2022-12-05 17:39:06.820301: E /samgraph/samgraph/common/dist/pre_sampler.cc:136] max_num_inputs = 1277636, min_num_inputs = 1248160
[2022-12-05 17:39:07. 26778: E /samgraph/samgraph/common/dist/pre_sampler.cc:148] presample spend 0.206379 on sort freq.
[2022-12-05 17:39:07.230878: E /samgraph/samgraph/common/dist/dist_engine.cc:524] pre sample done, delete it
[[[2022-12-05 17:39:072022-12-05 17:39:072022-12-05 17:39:07...246188246193246197: : : WWW   /samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc/samgraph/samgraph/common/dist/dist_engine.cc:::711711711] ] ] Trainer[2] building cache...Trainer[0] building cache...Trainer[1] building cache...


[2022-12-05 17:39:07.249097: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 17:39:07.249159: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:197] remote time is 8.68421
[2022-12-05 17:39:07.249189: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 17:39:07.249521: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[2022-12-05 17:39:07.249642: E [/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc2022-12-05 17:39:07:.197249629] : remote time is 8.68421E
 /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:196] build symm link desc with 3X Tesla V100-SXM2-16GB out of 4
[[2022-12-05 17:39:072022-12-05 17:39:07..249750249820: : EE  /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc/samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc::198197] ] cpu time is 30remote time is 8.68421

[2022-12-05 17:39:07.249977: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/asymm_link_desc.cc:198] cpu time is 30
[2022-12-05 17:39:25.831023: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:115] solver created. now build & solve
[2022-12-05 17:39:25.858099: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:120] solver built. now solve
[2022-12-05 17:39:25.858142: E /samgraph/3rdparty/collcachelib/coll_cache_lib/coll_cache/optimal_solver_class.cc:895] num_cached_nodes = 10497338
[2022-12-05 17:39:26.150938: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:124] solver solved
[2022-12-05 17:39:26.151040: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:187] 0 solved master
[2022-12-05 17:39:26.151086: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 0 solved
[2022-12-05 17:39:26.151115: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 0 thread 0 initing device 0
[2022-12-05 17:39:26.162836: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 2 solved
[2022-12-05 17:39:26.162887: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 2 thread 2 initing device 2
[2022-12-05 17:39:26.162942: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:194] 1 solved
[2022-12-05 17:39:26.163009: E /samgraph/3rdparty/collcachelib/coll_cache_lib/facade.cc:197] worker 1 thread 1 initing device 1
[2022-12-05 17:39:27.146431: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 10497338 / 65608366 nodes ( 16.00 %~16.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 55111028 / 65608366 nodes ( 84.00 %) | 10.01 GB | 0.99424 secs 
[2022-12-05 17:39:27.146755: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 10497338 / 65608366 nodes ( 16.00 %~16.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 55111028 / 65608366 nodes ( 84.00 %) | 10.01 GB | 0.982755 secs 
[2022-12-05 17:39:27.147414: E /samgraph/3rdparty/collcachelib/coll_cache_lib/cache_context.cu:1740] Collaborative GPU cache (policy: rep_cache) | local 10497338 / 65608366 nodes ( 16.00 %~16.00 %) | remote 0 / 65608366 nodes ( 0.00 %) | cpu 55111028 / 65608366 nodes ( 84.00 %) | 10.01 GB | 0.983254 secs 
[2022-12-05 17:39:35.461142: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.32 GB
[2022-12-05 17:39:36.625905: W /samgraph/samgraph/common/cuda/cuda_device.cc:49] GPU[0] alloc cuda memory 1.32 GB
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
/usr/local/lib/python3.8/dist-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
